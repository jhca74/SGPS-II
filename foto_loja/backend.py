from fastapi import FastAPI, File, UploadFile, HTTPExceptionfrom fastapi.responses import JSONResponse, FileResponsefrom fastapi.staticfiles import StaticFilesfrom fastapi.responses import HTMLResponsefrom fastapi.middleware.cors import CORSMiddlewarefrom PIL import Image, ImageEnhanceimport ioimport exifreadimport requestsfrom langchain_community.llms import Ollamafrom langchain.prompts import PromptTemplateimport cv2import numpy as npimport base64import piexifimport ollamaimport torchimport torchvision.transforms as Tapp = FastAPI()# Servir arquivos estÃ¡ticos da pasta 'static'app.mount("/static", StaticFiles(directory="static"), name="static")# Rota para a pÃ¡gina inicial (servir index.html)@app.get("/", response_class=HTMLResponse)async def get_index():    with open("static/index.html", "r", encoding="utf-8") as f:        return HTMLResponse(content=f.read())# ConfiguraÃ§Ã£o do CORSapp.add_middleware(    CORSMiddleware,    allow_origins=["*"],    allow_credentials=True,    allow_methods=["*"],    allow_headers=["*"],)# ConfiguraÃ§Ã£o do LangChain com Ollama usando llama3:8b-instruct-q4_0llm = Ollama(model="llama3:8b-instruct-q4_0")prompt_template = PromptTemplate(    input_variables=["location"],    template="Crie uma descriÃ§Ã£o lÃºdica de {location} em atÃ© 50 palavras, incluindo 3 hashtags relevantes.")# FunÃ§Ã£o para redimensionar a imagem (se necessÃ¡rio)def resize_image(image: Image.Image, max_width: int = 4000, max_height: int = 3000) -> Image.Image:    width, height = image.size    if width <= max_width and height <= max_height:        return image    aspect_ratio = width / height    if aspect_ratio > 1:        new_width = max_width        new_height = int(max_width / aspect_ratio)    else:        new_height = max_height        new_width = int(max_height * aspect_ratio)    return image.resize((new_width, new_height), Image.LANCZOS)# FunÃ§Ã£o para aumentar resoluÃ§Ã£o usando torchvision (substitui Real-ESRGAN)def enhance_resolution(image: Image.Image) -> Image.Image:    # Converter PIL Image para tensor    img_array = np.array(image)    img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).float() / 255.0  # (C, H, W)    # Aumentar resoluÃ§Ã£o (simples upscaling usando interpolate)    scale_factor = 4    new_size = (img_tensor.shape[1] * scale_factor, img_tensor.shape[2] * scale_factor)    img_tensor = torch.nn.functional.interpolate(        img_tensor.unsqueeze(0),  # Adiciona batch dimension        size=new_size,        mode='bicubic',        align_corners=False    ).squeeze(0)  # Remove batch dimension    # Converter tensor de volta para PIL Image    img_array = (img_tensor.permute(1, 2, 0).numpy() * 255).astype(np.uint8)    return Image.fromarray(img_array)# FunÃ§Ã£o para ajustar brilho e contrastedef adjust_brightness_contrast(image: Image.Image, brightness: float = 1.0, contrast: float = 1.0) -> Image.Image:    img_array = np.array(image)    img_array = img_array * brightness    img_array = img_array * contrast + (127 * (1 - contrast))    img_array = np.clip(img_array, 0, 255).astype(np.uint8)    return Image.fromarray(img_array)# FunÃ§Ã£o para ajustar nitidezdef adjust_sharpness(image: Image.Image, sharpness: float = 1.0) -> Image.Image:    enhancer = ImageEnhance.Sharpness(image)    return enhancer.enhance(sharpness)# FunÃ§Ã£o para ajustar saturaÃ§Ã£odef adjust_saturation(image: Image.Image, saturation: float = 1.0) -> Image.Image:    enhancer = ImageEnhance.Color(image)    return enhancer.enhance(saturation)# FunÃ§Ã£o para detectar pessoas (usando Llava)def detect_people(image: Image.Image) -> dict:    buffered = io.BytesIO()    image.save(buffered, format="JPEG")    img_base64 = base64.b64encode(buffered.getvalue()).decode()    response = ollama.generate(        model="llava",        prompt="Does this image contain people? If yes, estimate how many.",        images=[img_base64]    )    response_text = response.get("response", "").lower()    has_people = "yes" in response_text or "people" in response_text    people_count = int(response_text.split()[-1]) if has_people and response_text.split()[-1].isdigit() else 0    return {"has_people": has_people, "people_count": people_count}# FunÃ§Ã£o para classificar temas com Llavadef classify_themes(image: Image.Image) -> list:    buffered = io.BytesIO()    image.save(buffered, format="JPEG")    img_base64 = base64.b64encode(buffered.getvalue()).decode()    response = ollama.generate(        model="llava",        prompt="Identify the main themes in this image (e.g., beach, mountains, people). Return a comma-separated list.",        images=[img_base64]    )    themes = response.get("response", "").split(", ")    return themes if themes and themes[0] else ["geral"]# FunÃ§Ã£o para remover metadadosdef remove_metadata(image_data: bytes) -> bytes:    image = Image.open(io.BytesIO(image_data))    buffered = io.BytesIO()    image.save(buffered, format="JPEG", exif=b"", quality=85)    return buffered.getvalue()# Endpoint para processar imagem@app.post("/process_image")async def process_image(file: UploadFile = File(...), edit_terms: str = ""):    if not file.content_type.startswith("image/"):        raise HTTPException(status_code=400, detail="O arquivo deve ser uma imagem (JPEG ou PNG).")    image_data = await file.read()    if len(image_data) > 50 * 1024 * 1024:        raise HTTPException(status_code=400, detail="O arquivo Ã© muito grande. O limite Ã© 50 MB.")    try:        image = Image.open(io.BytesIO(image_data))    except Exception as e:        raise HTTPException(status_code=400, detail=f"Erro ao abrir a imagem: {str(e)}")    original_image = image    if "aumentar resoluÃ§Ã£o" not in edit_terms.lower():        image = resize_image(image, max_width=4000, max_height=3000)    # Ajustes de imagem com validaÃ§Ã£o    try:        if "preto e branco" in edit_terms.lower():            image = image.convert("L")        if "vibrante" in edit_terms.lower():            image = image.point(lambda x: x * 1.2)        if "brilho" in edit_terms.lower():            brightness = float(edit_terms.split("brilho")[-1].strip().split()[0])            if not 0.1 <= brightness <= 5.0:                raise ValueError("O valor de brilho deve estar entre 0.1 e 5.0")            image = adjust_brightness_contrast(image, brightness=brightness)        if "contraste" in edit_terms.lower():            contrast = float(edit_terms.split("contraste")[-1].strip().split()[0])            if not 0.1 <= contrast <= 5.0:                raise ValueError("O valor de contraste deve estar entre 0.1 e 5.0")            image = adjust_brightness_contrast(image, contrast=contrast)        if "nitidez" in edit_terms.lower():            sharpness = float(edit_terms.split("nitidez")[-1].strip().split()[0])            if not 0.0 <= sharpness <= 10.0:                raise ValueError("O valor de nitidez deve estar entre 0.0 e 10.0")            image = adjust_sharpness(image, sharpness=sharpness)        if "saturacao" in edit_terms.lower():            saturation = float(edit_terms.split("saturacao")[-1].strip().split()[0])            if not 0.0 <= saturation <= 5.0:                raise ValueError("O valor de saturaÃ§Ã£o deve estar entre 0.0 e 5.0")            image = adjust_saturation(image, saturation=saturation)        if "rotacao" in edit_terms.lower():            rotation = float(edit_terms.split("rotacao")[-1].strip().split()[0])            if not -360 <= rotation <= 360:                raise ValueError("O valor de rotaÃ§Ã£o deve estar entre -360 e 360 graus")            image = image.rotate(rotation, expand=True, fillcolor="white")    except ValueError as e:        raise HTTPException(status_code=400, detail=f"Erro nos parÃ¢metros de ediÃ§Ã£o: {str(e)}")    except IndexError as e:        raise HTTPException(status_code=400, detail=f"Erro nos parÃ¢metros de ediÃ§Ã£o: ParÃ¢metro mal formatado")    # Extrair metadados    tags = exifread.process_file(io.BytesIO(image_data))    gps_lat = tags.get("GPS GPSLatitude")    gps_lon = tags.get("GPS GPSLongitude")    location = "Desconhecida"    description = "Nenhuma descriÃ§Ã£o disponÃ­vel."    if gps_lat and gps_lon:        try:            lat = float(gps_lat.values[0].num / gps_lat.values[0].den)            lon = float(gps_lon.values[0].num / gps_lon.values[0].den)            response = requests.get(                f"https://nominatim.openstreetmap.org/reverse?format=json&lat={lat}&lon={lon}",                timeout=5            )            if response.status_code == 200:                location = response.json().get("display_name", "Desconhecida")                chain = prompt_template | llm                description = chain.invoke({"location": location})            else:                location = "Erro ao obter localizaÃ§Ã£o"        except requests.exceptions.RequestException as e:            location = "Erro de conexÃ£o ao obter localizaÃ§Ã£o"            description = f"Falha na geocodificaÃ§Ã£o: {str(e)}"    # Aumentar resoluÃ§Ã£o    if "aumentar resoluÃ§Ã£o" in edit_terms.lower():        try:            image = enhance_resolution(original_image)            image = resize_image(image, max_width=8000, max_height=6000)        except Exception as e:            raise HTTPException(status_code=500, detail=f"Erro ao aumentar resoluÃ§Ã£o: {str(e)}")    # Reconhecimento visual    try:        people_info = detect_people(image)        themes = classify_themes(image)    except Exception as e:        raise HTTPException(status_code=500, detail=f"Erro no reconhecimento visual: {str(e)}")    # Organizar resultados    result = {        "location": location,        "description": description,        "themes": themes,        "people": people_info,    }    # Comprimir a imagem resultante    buffered = io.BytesIO()    image.save(buffered, format="JPEG", quality=85)    img_base64 = base64.b64encode(buffered.getvalue()).decode()    return JSONResponse(content={"image": img_base64, "metadata": result})# Endpoint para remover metadados@app.post("/remove_metadata")async def remove_metadata_endpoint(file: UploadFile = File(...)):    if not file.content_type.startswith("image/"):        raise HTTPException(status_code=400, detail="O arquivo deve ser uma imagem (JPEG ou PNG).")    image_data = await file.read()    if len(image_data) > 50 * 1024 * 1024:        raise HTTPException(status_code=400, detail="O arquivo Ã© muito grande. O limite Ã© 50 MB.")    try:        cleaned_data = remove_metadata(image_data)        return FileResponse(io.BytesIO(cleaned_data), media_type="image/jpeg", filename="image_no_metadata.jpg")    except Exception as e:        raise HTTPException(status_code=500, detail=f"Erro ao remover metadados: {str(e)}")