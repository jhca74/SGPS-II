import osimport reimport hashlibfrom pathlib import Pathfrom typing import List, Dictfrom datetime import datetimeclass IntelligentCleaner:    def __init__(self):        self.stats = {            'deleted_files': 0,            'freed_space': 0,            'errors': 0,            'skipped_files': 0        }    def clean_duplicate_files(self, locations: List[str]) -> List[str]:        deleted = []        duplicates = self._find_duplicates(locations)        for file_hash, files in duplicates.items():            if len(files) > 1:                sorted_files = sorted(                    files,                    key=lambda x: (-os.path.getmtime(x), -os.path.getsize(x))                )                to_keep = sorted_files[0]                for file in sorted_files[1:]:                    try:                        file_size = os.path.getsize(file)                        os.remove(file)                        self.stats['deleted_files'] += 1                        self.stats['freed_space'] += file_size                        deleted.append(file)                    except:                        self.stats['errors'] += 1        # sugestÃ£o removida: "clean_duplicate_files")        return deleted    def clean_numbered_files(self, locations: List[str]) -> List[str]:        deleted = []        pattern = re.compile(r'^(.*?)\((\d+)\)(\.[^.]*)?$')        for location in locations:            for root, _, files in os.walk(location):                groups = {}                for file in files:                    match = pattern.fullmatch(file)                    if match:                        base_name = match.group(1)                        ext = match.group(3) or ''                        full_base = base_name + ext                        groups.setdefault(full_base, []).append(file)                for base_name, numbered_files in groups.items():                    original_path = os.path.join(root, base_name)                    if os.path.exists(original_path):                        for numbered_file in numbered_files:                            try:                                file_path = os.path.join(root, numbered_file)                                file_size = os.path.getsize(file_path)                                os.remove(file_path)                                self.stats['deleted_files'] += 1                                self.stats['freed_space'] += file_size                                deleted.append(file_path)                            except:                                self.stats['errors'] += 1        # sugestÃ£o removida: "clean_numbered_files")        return deleted    def clean_old_backups(self, locations: List[str]) -> List[str]:        deleted = []        backup_patterns = [            r'backup', r'bak', r'cÃ³pia', r'old', r'antigo',            r'\d{4}-\d{2}-\d{2}', r'\d{8}', r'v\d+', r'versao\d+',            r'novo_padrao'        ]        for location in locations:            for root, _, files in os.walk(location):                for file in files:                    if any(re.search(pattern, file.lower()) for pattern in backup_patterns):                        file_path = os.path.join(root, file)                        try:                            file_time = os.path.getmtime(file_path)                            if (datetime.now().timestamp() - file_time) > 60 * 24 * 3600:                                file_size = os.path.getsize(file_path)                                os.remove(file_path)                                self.stats['deleted_files'] += 1                                self.stats['freed_space'] += file_size                                deleted.append(file_path)                        except:                            self.stats['errors'] += 1        # sugestÃ£o removida: "clean_old_backups")        return deleted    def clean_update_packages(self, locations: List[str]) -> List[str]:        deleted = []        update_keywords = ['update', 'patch', 'hotfix', 'kb', 'msp']        for location in locations:            for root, _, files in os.walk(location):                for file in files:                    if any(keyword in file.lower() for keyword in update_keywords):                        if file.lower().endswith(('.msi', '.msp', '.cab', '.exe')):                            file_path = os.path.join(root, file)                            try:                                file_time = os.path.getmtime(file_path)                                if (datetime.now().timestamp() - file_time) > 180 * 24 * 3600:                                    file_size = os.path.getsize(file_path)                                    os.remove(file_path)                                    self.stats['deleted_files'] += 1                                    self.stats['freed_space'] += file_size                                    deleted.append(file_path)                            except:                                self.stats['errors'] += 1        # sugestÃ£o removida: "clean_update_packages")        return deleted    def clean_uninstall_residues(self, locations: List[str]) -> List[str]:        deleted = []        residue_patterns = [            r'unins', r'uninst', r'desinst', r'remove', r'deinstall',            r'~$', r'\.tmp$', r'\.bak$', r'\.old$'        ]        for location in locations:            for root, _, files in os.walk(location):                for file in files:                    if any(re.search(pattern, file.lower()) for pattern in residue_patterns):                        file_path = os.path.join(root, file)                        try:                            file_size = os.path.getsize(file_path)                            os.remove(file_path)                            self.stats['deleted_files'] += 1                            self.stats['freed_space'] += file_size                            deleted.append(file_path)                        except:                            self.stats['errors'] += 1        # sugestÃ£o removida: "clean_uninstall_residues")        return deleted    def clean_unnecessary_dlls(self, locations: List[str]) -> List[str]:        deleted = []        common_dlls = set()        for location in locations:            for root, _, files in os.walk(location):                for file in files:                    if file.lower().endswith('.exe'):                        try:                            with open(os.path.join(root, file), 'rb') as f:                                content = f.read()                                dll_refs = re.findall(rb'[A-Za-z0-9_\-]+\.dll', content)                                common_dlls.update(d.lower().decode() for d in dll_refs)                        except:                            pass        for location in locations:            for root, _, files in os.walk(location):                for file in files:                    if file.lower().endswith('.dll') and file.lower() not in common_dlls:                        file_path = os.path.join(root, file)                        try:                            file_size = os.path.getsize(file_path)                            os.remove(file_path)                            self.stats['deleted_files'] += 1                            self.stats['freed_space'] += file_size                            deleted.append(file_path)                        except:                            self.stats['errors'] += 1        # sugestÃ£o removida: "clean_unnecessary_dlls")        return deleted    def clean_empty_folders(self, locations: List[str]) -> List[str]:        deleted = []        for location in locations:            for root, dirs, _ in os.walk(location, topdown=False):                for dir in dirs:                    dir_path = os.path.join(root, dir)                    try:                        if not os.listdir(dir_path):                            os.rmdir(dir_path)                            self.stats['deleted_files'] += 1                            deleted.append(dir_path)                    except:                        self.stats['errors'] += 1        return deleted    def _find_duplicates(self, locations: List[str]) -> Dict[str, List[str]]:        hashes = {}        for location in locations:            for root, _, files in os.walk(location):                for file in files:                    file_path = os.path.join(root, file)                    try:                        file_hash = self._calculate_hash(file_path)                        hashes.setdefault(file_hash, []).append(file_path)                    except:                        self.stats['errors'] += 1        return {h: p for h, p in hashes.items() if len(p) > 1}    def _calculate_hash(self, filepath: str, buffer_size=65536) -> str:        md5 = hashlib.md5()        with open(filepath, 'rb') as f:            while chunk := f.read(buffer_size):                md5.update(chunk)        return md5.hexdigest()