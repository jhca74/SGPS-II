import requestsfrom bs4 import BeautifulSoupfrom datetime import datetimeimport osDESTINO = "memoria/indexado/web/"URLS = [    "https://html.duckduckgo.com/html/",    "https://github.com",    "https://www.wikipedia.org",]HEADERS = {    "User-Agent": "Mozilla/5.0",    "Accept-Language": "pt-PT,pt;q=0.9",}def scrapear_url(url):    try:        response = requests.get(url, headers=HEADERS, timeout=10)        if response.status_code == 200:            soup = BeautifulSoup(response.text, 'html.parser')            texto = soup.get_text()            guardar_texto(url, texto)        else:            print(f"[ERRO] Falha ao aceder {url}: HTTP {response.status_code}")    except Exception as e:        print(f"[ERRO] ExceÃ§Ã£o ao aceder {url}: {e}")def guardar_texto(url, texto):    domain = url.split("//")[-1].split("/")[0].replace(".", "_")    filename = f"{domain}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"    os.makedirs(DESTINO, exist_ok=True)    with open(os.path.join(DESTINO, filename), "w", encoding="utf-8") as f:        f.write(texto)    print(f"[OK] ConteÃºdo guardado: {filename}")def scraping_externo():    for url in URLS:        scrapear_url(url)if __name__ == "__main__":    scraping_externo()